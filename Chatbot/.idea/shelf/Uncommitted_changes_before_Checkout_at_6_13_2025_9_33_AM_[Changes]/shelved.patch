Index: APIs/recommendation_APIs/activities_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/APIs/recommendation_APIs/activities_api.py b/APIs/recommendation_APIs/activities_api.py
deleted file mode 100644
--- a/APIs/recommendation_APIs/activities_api.py	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
+++ /dev/null	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
@@ -1,136 +0,0 @@
-import requests
-from config_helper import get_db_params, get_api_urls
-from fastapi import FastAPI, HTTPException
-from contextlib import contextmanager
-import psycopg2
-from psycopg2 import pool
-from pydantic import BaseModel
-from typing import List
-import time
-import logging
-
-app = FastAPI()
-logger = logging.getLogger(__name__)
-
-EMBEDDING_API_URL = get_api_urls().get('embedding')
-DB_Prams = get_db_params()
-ACTIVITY_QUERY = """
-    SELECT activity_id, A.name, A.description, 1 - (A.embedding <=> %s::vector) AS similarity , price , A.duration_in_hours
-    FROM activities A 
-    JOIN states S ON A.state_id = S.state_id
-    WHERE lower(S.name) LIKE %s 
-    ORDER BY similarity desc limit 50
-"""
-
-
-# Create a connection pool
-connection_pool = pool.ThreadedConnectionPool(
-    minconn=1,
-    maxconn=10,
-    **DB_Prams
-)
-
-class ActivityRequestByText(BaseModel):
-    city_name: str
-    user_message: str
-    preferred_activities: List[str]
-
-@app.post("/api/activities/search")
-def get_activities(request: ActivityRequestByText):
-    try:
-        with get_db_connection() as conn:
-            # Search for Activities by user message
-            activities_by_message = get_activities_by_text(conn, request.city_name, request.user_message)
-
-            # Search for Activities by user activities
-            activities_by_user_activities = []
-            if request.preferred_activities:
-                activities_by_user_activities = get_activities_by_user_activities(conn, request.city_name, request.preferred_activities)
-
-            activity_list = activities_by_message + activities_by_user_activities
-
-            # remove duplicates
-            activity_list = list({activity['id']: activity for activity in activity_list}.values())
-            # sort by similarity
-            activity_list.sort(key=lambda x: x['score'], reverse=True)
-
-            return {"activities": activity_list}
-    except Exception as e:
-        logger.error(f"Error in get_activities: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")
-
-
-@contextmanager
-def get_db_connection():
-    conn = None
-    max_retries = 3
-    retry_delay = 1  # seconds
-
-    for attempt in range(max_retries):
-        try:
-            conn = connection_pool.getconn()
-            yield conn
-            break
-        except psycopg2.OperationalError as e:
-            logger.error(f"Database connection attempt {attempt + 1} failed: {str(e)}")
-            if attempt == max_retries - 1:
-                raise HTTPException(status_code=500, detail="Database connection failed after multiple attempts")
-            time.sleep(retry_delay)
-            retry_delay *= 2
-        finally:
-            if conn:
-                try:
-                    connection_pool.putconn(conn)
-                except Exception as e:
-                    logger.error(f"Error returning connection to pool: {str(e)}")
-
-
-def convert_row_to_dict(row: tuple):
-    ret = {
-        "id": row[0],
-        "name": row[1],
-        "description": row[2],
-        "score": row[3],
-        "price": row[4],
-        'duration': row[5]
-    }
-    return ret
-
-
-def get_embedding(text: str) -> List[float]:
-    response = requests.post(EMBEDDING_API_URL, json={"text": text})
-    if response.status_code != 200:
-        raise HTTPException(status_code=500, detail="Error getting embedding")
-    return response.json().get("embedding")
-
-def get_activities_by_text(conn, city_name, user_massage):
-    with conn.cursor() as cursor:
-        # get the embedding for the user message
-        embedding = get_embedding(user_massage)
-        cursor.execute(ACTIVITY_QUERY, (embedding, '%' + city_name.lower() + '%', ))
-        result = cursor.fetchall()
-        result= [convert_row_to_dict(row) for row in result]
-
-        return result
-
-def get_activities_by_user_activities(conn, city_name, user_activities):
-    activities_list = []
-    with conn.cursor() as cursor:
-        for activity in user_activities:
-            # get the embedding for the activity
-            embedding = get_embedding(activity)
-            cursor.execute(ACTIVITY_QUERY, (embedding, '%' + city_name.lower() + '%',))
-            activities_list.extend(convert_row_to_dict(row) for row in cursor.fetchall())
-        activities_list = list({activity['id']: activity for activity in activities_list}.values())
-
-        return activities_list
-
-
-if __name__ == "__main__":
-    import uvicorn
-    try:
-        uvicorn.run(app, host="0.0.0.0", port=3002)
-    finally:
-        if connection_pool:
-            connection_pool.closeall()
-
Index: APIs/recommendation_APIs/landmarks_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/APIs/recommendation_APIs/landmarks_api.py b/APIs/recommendation_APIs/landmarks_api.py
deleted file mode 100644
--- a/APIs/recommendation_APIs/landmarks_api.py	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
+++ /dev/null	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
@@ -1,131 +0,0 @@
-import requests
-from config_helper import get_db_params, get_api_urls
-from fastapi import FastAPI, HTTPException
-from contextlib import contextmanager
-import psycopg2
-from psycopg2 import pool
-from pydantic import BaseModel
-from typing import List
-import time
-import logging
-
-app = FastAPI()
-logger = logging.getLogger(__name__)
-
-EMBEDDING_API_URL = get_api_urls().get('embedding')
-DB_Prams = get_db_params()
-
-LANDMARK_QUERY = """
-    SELECT landmark_id, L.name, L.description, 1 - (L.embedding <=> %s::vector) AS similarity, price_foreign, L.longitude, L.latitude
-    FROM landmarks L join states S on L.state_id = S.state_id
-    WHERE lower(S.name) LIKE %s
-    ORDER BY similarity desc
-   """
-
-# Create a connection pool
-connection_pool = pool.ThreadedConnectionPool(
-    minconn=1,
-    maxconn=10,
-    **DB_Prams
-)
-
-class LandmarksRequestByText(BaseModel):
-    city_name: str
-    user_message: str
-    preferred_landmarks: List[str]
-
-@app.post("/api/landmarks/search")
-def get_landmarks(request: LandmarksRequestByText):
-    try:
-        with get_db_connection() as conn:
-            # Search for Landmarks by user message
-            landmarks_by_message = get_landmark_by_text(conn, request.city_name, request.user_message)
-
-            # Search for Landmarks by user activities
-            landmarks_by_user_activities = []
-            if request.preferred_landmarks:
-                landmarks_by_user_activities = get_landmark_by_user_activities(conn, request.city_name, request.preferred_landmarks)
-
-            landmark_list = landmarks_by_message + landmarks_by_user_activities
-
-            # remove duplicates
-            landmark_list = list({landmark['id']: landmark for landmark in landmark_list}.values())
-            # sort by similarity
-            landmark_list.sort(key=lambda x: x['score'], reverse=True)
-
-            return {"landmarks": landmark_list}
-    except Exception as e:
-        logger.error(f"Error in get_landmarks: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")
-
-
-@contextmanager
-def get_db_connection():
-    conn = None
-    max_retries = 3
-    retry_delay = 1
-    for attempt in range(max_retries):
-        try:
-            conn = connection_pool.getconn()
-            yield conn
-            break
-        except psycopg2.OperationalError as e:
-            logger.error(f"Database connection attempt {attempt + 1} failed: {str(e)}")
-            if attempt == max_retries - 1:
-                raise HTTPException(status_code=500, detail="Database connection failed after multiple attempts")
-            time.sleep(retry_delay)
-            retry_delay *= 2
-        finally:
-            if conn:
-                try:
-                    connection_pool.putconn(conn)
-                except Exception as e:
-                    logger.error(f"Error returning connection to pool: {str(e)}")
-
-
-def convert_row_to_dict(row: tuple, kind):
-    ret = {
-        "id": row[0],
-        "name": row[1],
-        "description": row[2],
-        "score": row[3],
-        "price": row[4]
-    }
-    if kind == 'a':
-        ret['duration'] = row[5]
-    else:
-        ret['longitude'] = row[5]
-        ret['latitude'] = row[6]
-    return ret
-
-
-def get_embedding(text: str) -> List[float]:
-    response = requests.post(EMBEDDING_API_URL, json={"text": text})
-    if response.status_code != 200:
-        raise HTTPException(status_code=500, detail="Error getting embedding")
-    return response.json().get("embedding")
-
-def get_landmark_by_text(conn, city_name, user_massage):
-    with conn.cursor() as cursor:
-        # get the embedding for the user message
-        embedding = get_embedding(user_massage)
-        cursor.execute(LANDMARK_QUERY, (embedding, '%' + city_name.lower() + '%', ))
-        result = cursor.fetchall()
-        return [convert_row_to_dict(row,'l') for row in result]
-def get_landmark_by_user_activities(conn, city_name, user_activities):
-    landmarks_list = []
-    with conn.cursor() as cursor:
-        for landmark in user_activities:
-            # get the embedding for the activity
-            embedding = get_embedding(landmark)
-            cursor.execute(LANDMARK_QUERY, (embedding, '%' + city_name.lower() + '%',))
-            landmarks_list.extend(convert_row_to_dict(row,'l') for row in cursor.fetchall())
-        return list({landmark['id']: landmark for landmark in landmarks_list}.values())
-
-if __name__ == "__main__":
-    import uvicorn
-    try:
-        uvicorn.run(app, host="0.0.0.0", port=3004)
-    finally:
-        if connection_pool:
-            connection_pool.closeall()
Index: APIs/recommendation_APIs/plans_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/APIs/recommendation_APIs/plans_api.py b/APIs/recommendation_APIs/plans_api.py
deleted file mode 100644
--- a/APIs/recommendation_APIs/plans_api.py	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
+++ /dev/null	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
@@ -1,125 +0,0 @@
-import heapq
-import requests
-from APIs.test_recommendaaation_model import calculate_similarity
-from config_helper import get_db_params, get_api_urls
-from fastapi import FastAPI, HTTPException
-from contextlib import contextmanager
-import psycopg2
-from pydantic import BaseModel
-from typing import List
-
-app = FastAPI()
-
-class PlanRequest(BaseModel):
-    city_name: str
-    budget: float
-    duration: int
-    suggested_hotels: List[dict]
-    suggested_activities: List[dict]
-    suggested_landmarks: List[dict]
-
-def search_optimal_items(budget, activity_landmark_options):
-    scale = 100
-
-    max_b= int(budget*scale)+1
-    dp=[0]*max_b
-    selected_options=[[] for _ in range(max_b)]
-    for option in activity_landmark_options:
-        price = int(option['price']*scale)
-        if price <= 0:
-            continue
-        for b in range(max_b-1,price-1,-1):
-            new_value=dp[b-price]+option['score']
-            if new_value>dp[b]:
-                dp[b]=new_value
-                selected_options[b]=selected_options[b-price]+[option]
-    max_value = 0
-    max_index = 0
-    for i in range(max_b):
-        if dp[i]>max_value:
-            max_value=dp[i]
-            max_index=i
-    return max_value,selected_options[max_index]
-
-def seperate_activities_landmarks(selected_options,activities,landmarks):
-    activities_options=[item for item in selected_options if item in activities]
-    landmarks_options=[item for item in selected_options if item in landmarks]
-    return activities_options[:5],landmarks_options[:5]
-def calculate_similarity(comb1, comb2):
-    hotel_overlap = int(comb1['hotel']['hotel_id'] == comb2['hotel']['hotel_id'])
-    activity_overlap = len(set(a['id'] for a in comb1['activities']) & set(a['id'] for a in comb2['activities']))
-    landmark_overlap = len(set(l['id'] for l in comb1['landmarks']) & set(l['id'] for l in comb2['landmarks']))
-    return hotel_overlap + activity_overlap + landmark_overlap
-
-
-
-def find_best_plan_options(hotels, activities, landmarks, budget, duration):
-   activity_landmark_options = activities + landmarks
-   for item_list in activity_landmark_options:
-        for key,item in item_list.items():
-            if key=='price'and item is None:
-                item_list['price'] = 0.0
-   best_options = []
-   activity_landmark_options.sort(key=lambda x: x['score'], reverse=True)
-   for hotel in hotels:
-       hotel['price_per_night'] *= duration
-       remaining_budget = budget - hotel['price_per_night']
-       if remaining_budget <= 0:
-           continue
-       options_score,selected_options = search_optimal_items(remaining_budget, activity_landmark_options)
-       options_cost=sum( a["price"]for a in selected_options)
-       total_cost = options_cost+ hotel['price_per_night']
-       total_score = options_score+hotel['score']
-       activities_options,landmarks_options=seperate_activities_landmarks(selected_options,activities,landmarks)
-
-       plan_combination = {
-           "hotel": hotel,
-           "activities": activities_options,
-           "landmarks": landmarks_options,
-           "total_score": total_score,
-           "total_plan_cost": total_cost
-       }
-       if len(best_options) < 3:
-            heapq.heappush(best_options,  (total_score, plan_combination))
-       elif total_score > best_options[0][0]:
-           heapq.heappushpop(best_options, (total_score,plan_combination))
-
-
-   suggestion=[item[1] for item in sorted(best_options,key=lambda  x:x[0],reverse=True)]
-   
-   return suggestion
-
-
-
-@app.post("/api/plans")
-def create_plan(request: PlanRequest):
-    plan_combinations = find_best_plan_options(
-        request.suggested_hotels,
-        request.suggested_activities,
-        request.suggested_landmarks,
-        request.budget,
-        request.duration
-    )
-    displayed_plan_combinations = []
-    for plan_combination in plan_combinations:
-        temp = {}
-        for key, value in plan_combination.items():
-            if key == 'total_score':
-                continue
-
-            if key == 'hotel':
-                # Keep all hotel fields
-                temp[key] = value
-            elif key in ['activities', 'landmarks']:
-                # Keep all fields for activities and landmarks
-                temp[key] = value
-            else:
-                # Handle other keys normally
-                temp[key] = value
-
-        displayed_plan_combinations.append(temp)
-    return {"plan_combinations": displayed_plan_combinations}
-
-if __name__ == "__main__":
-    import uvicorn
-    uvicorn.run(app, host="0.0.0.0", port=3003)
Index: APIs/recommendation_APIs/hotels_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/APIs/recommendation_APIs/hotels_api.py b/APIs/recommendation_APIs/hotels_api.py
deleted file mode 100644
--- a/APIs/recommendation_APIs/hotels_api.py	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
+++ /dev/null	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
@@ -1,211 +0,0 @@
-from rapidfuzz import fuzz
-from config_helper import get_db_params
-from fastapi import FastAPI, HTTPException
-import psycopg2
-from psycopg2 import pool
-from pydantic import BaseModel
-from typing import List
-import math
-import logging
-import time
-
-app = FastAPI()
-logger = logging.getLogger(__name__)
-
-DB_Prams = get_db_params()
-
-# Create a connection pool
-connection_pool = pool.ThreadedConnectionPool(
-    minconn=1,
-    maxconn=10,
-    **DB_Prams
-)
-
-def best_match_score(query, choices):
-    scores = []
-    for choice in choices:
-        score = max(
-            fuzz.ratio(query, choice),
-            fuzz.partial_ratio(query, choice),
-            fuzz.token_sort_ratio(query, choice),
-            fuzz.token_set_ratio(query, choice)
-        )
-        scores.append((choice, score))
-    best = max(scores, key=lambda x: x[1])
-    return best
-
-def get_facilities_ids(conn, user_facilities):
-    try:
-        with conn.cursor() as cur:
-            select_query = """SELECT facility_id , name from hotel_facilities """
-            cur.execute(select_query,)
-            facilities_ids = cur.fetchall()
-            # search for the facilities in the rooms
-            select_query = """SELECT room_facility_id, name FROM room_facilities"""
-            cur.execute(select_query)
-            room_facilities= cur.fetchall()
-            all_facilities =  facilities_ids + room_facilities
-            facilities_names = [facility[1] for facility in all_facilities]
-            facilities_dic = {}
-            # Use fuzzy matching to find the best match for each user facility
-            for user_facility in user_facilities:
-                match, best_match = best_match_score(user_facility.lower(), [name.lower() for name in facilities_names])
-                logger.info(f"Facility matching: {match}, {best_match}, {user_facility}")
-                if  best_match >= 80:
-                    for f_id, name in all_facilities:
-                        if name.lower() == match:
-                            facilities_dic[user_facility] = f_id
-                            break
-
-            return facilities_dic
-    except Exception as e:
-        logger.error(f"Error in get_facilities_ids: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Error getting facilities: {str(e)}")
-
-def get_hotels_facilities(conn, city_name, facilities_ids, price_limit_per_night):
-    try:
-        with conn.cursor() as cur:
-            select_query = '''SELECT h.hotel_id, h.name, r.total_price,h.longitude,h.latitude,hf.facility_id, hf.name
-                            FROM hotels h
-                            JOIN hotels_facilities_rel hfr ON h.hotel_id = hfr.hotel_id
-                            JOIN hotel_facilities hf ON hfr.facility_id = hf.facility_id
-                            JOIN rooms r ON h.hotel_id = r.hotel_id
-                            JOIN states s ON h.state_id = s.state_id
-                            WHERE lower(s.name) LIKE %s and hf.facility_id = ANY(%s)
-                            and r.total_price <= %s limit 10'''
-            cur.execute(select_query, ('%' + city_name.lower() + '%',facilities_ids, price_limit_per_night))
-            result = cur.fetchall()
-            hotels = {}
-            for hotel in result:
-                if hotel[0] not in hotels:
-                    hotels[hotel[0]]={
-                        "hotel_id": hotel[0],
-                        "hotel_name": hotel[1],
-                        "price_per_night": hotel[2],
-                        "longitude": hotel[3],
-                        "latitude": hotel[4],
-                        "facilities_ids": set(),
-                        "facilities": set()
-                    }
-                hotels[hotel[0]]["facilities_ids"].add(hotel[5])
-                hotels[hotel[0]]["facilities"].add(hotel[6])
-
-            return hotels
-    except Exception as e:
-        logger.error(f"Error in get_hotels_facilities: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Error getting hotels: {str(e)}")
-
-def calculate_matching_score(hotel_facilities, user_facilities):
-    try:
-        total_user_facilities = len(user_facilities)
-        # Calculate the minimum and maximum price for normalization
-        prices = [hotel["price_per_night"] for hotel in hotel_facilities.values()
-                        if  not math.isnan(hotel["price_per_night"])]
-        min_price = min(prices) if prices else 0
-        max_price = max(prices) if prices else 0
-        alpha= 0.7
-        beta=0.3
-
-        for hotel_id,hotel_data in hotel_facilities.items():
-            matched_facilities = hotel_data["facilities"].intersection(user_facilities)
-            matching_score = len(matched_facilities) / total_user_facilities if total_user_facilities else 0
-
-            # Normalize the price to a score between 0 and 1
-            if math.isnan(hotel_data["price_per_night"])  or max_price == min_price:
-                normalized_price = 0.0
-            else:
-                normalized_price = 1 - (hotel_data["price_per_night"] - min_price) / (max_price - min_price)
-
-            # Calculate the final score
-            normalized_score= alpha * matching_score + beta * normalized_price
-
-            hotel_data["score"] = normalized_score
-
-        # Sort hotels by matching score in descending order
-        sorted_hotels = sorted(hotel_facilities.values(), key=lambda x: x["score"], reverse=True)
-        return sorted_hotels
-    except Exception as e:
-        logger.error(f"Error in calculate_matching_score: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Error calculating scores: {str(e)}")
-
-class HotelRequest(BaseModel):
-    city_name: str
-    duration: int
-    budget: float
-    user_facilities: List[str]
-
-@app.post("/api/hotels/search")
-def get_hotels(request: HotelRequest):
-    conn = None
-    try:
-        logger.info(f"Received request for city: {request.city_name}, facilities: {request.user_facilities}")
-        
-        # Get connection from pool with retry logic
-        max_retries = 3
-        retry_delay = 1
-        for attempt in range(max_retries):
-            try:
-                conn = connection_pool.getconn()
-                break
-            except psycopg2.OperationalError as e:
-                logger.error(f"Database connection attempt {attempt + 1} failed: {str(e)}")
-                if attempt == max_retries - 1:
-                    raise HTTPException(status_code=500, detail="Database connection failed after multiple attempts")
-                time.sleep(retry_delay)
-                retry_delay *= 2
-
-        # get all the hotels in the city with the user preferences
-        facilities_ids = get_facilities_ids(conn, request.user_facilities)
-        logger.info(f"Found facilities IDs: {facilities_ids}")
-        
-        if not facilities_ids:
-            raise HTTPException(status_code=400, detail="No matching facilities found for the provided preferences")
-            
-        price_limit_per_night = request.budget / request.duration
-        logger.info(f"Price limit per night: {price_limit_per_night}")
-        
-        hotels_facilitates = get_hotels_facilities(conn, request.city_name, list(facilities_ids.values()), price_limit_per_night)
-        logger.info(f"Found hotels with facilities: {len(hotels_facilitates)}")
-        
-        if not hotels_facilitates:
-            raise HTTPException(status_code=404, detail=f"No hotels found in {request.city_name} matching your criteria")
-            
-        # calculate the matching score for each hotel
-        sorted_hotels = calculate_matching_score(hotels_facilitates, set(request.user_facilities))
-
-        hotels = []
-        for hotel in sorted_hotels:
-            hotel_data = {
-                'hotel_id': hotel['hotel_id'],
-                "hotel_name": hotel["hotel_name"],
-                "longitude": hotel["longitude"],
-                "latitude": hotel["latitude"],
-                "facilities": list(hotel["facilities"]),
-                "score": hotel["score"]
-            }
-
-            # Handle NaN values in price
-            if math.isnan(hotel["price_per_night"]):
-                hotel_data["price_per_night"] = None
-            else:
-                hotel_data["price_per_night"] = hotel["price_per_night"]
-
-            hotels.append(hotel_data)
-        return {"hotels": hotels}
-    except Exception as e:
-        logger.error(f"Error in get_hotels: {str(e)}")
-        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")
-    finally:
-        if conn:
-            try:
-                connection_pool.putconn(conn)
-            except Exception as e:
-                logger.error(f"Error returning connection to pool: {str(e)}")
-
-if __name__ == "__main__":
-    import uvicorn
-    try:
-        uvicorn.run(app, host="0.0.0.0", port=3001)
-    finally:
-        if connection_pool:
-            connection_pool.closeall()
\ No newline at end of file
Index: APIs/recommendation_APIs/cities_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/APIs/recommendation_APIs/cities_api.py b/APIs/recommendation_APIs/cities_api.py
deleted file mode 100644
--- a/APIs/recommendation_APIs/cities_api.py	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
+++ /dev/null	(revision b78c357bd00fdab1540e0d618734570ecfef821e)
@@ -1,175 +0,0 @@
-import requests
-from pydantic import BaseModel
-from config_helper import get_db_params, get_api_urls
-from fastapi import FastAPI, HTTPException, Request
-import psycopg2
-import re
-import json
-
-
-
-
-app = FastAPI()
-
-EMBEDDING_API_URL = get_api_urls().get('embedding')
-DB_Prams = get_db_params()
-
-# Define common features and their keywords with weights
-FEATURES = {
-    'sea': {
-        'keywords': ['sea', 'beach', 'coast', 'shore', 'ocean', 'mediterranean', 'red sea'],
-        'weight': 1.5  # Higher weight for sea-related features
-    },
-    'desert': {
-        'keywords': ['desert', 'sahara', 'sand', 'oasis'],
-        'weight': 1.2
-    },
-    'historical': {
-        'keywords': ['historical', 'ancient', 'pharaonic', 'temple', 'pyramid', 'museum'],
-        'weight': 1.3
-    },
-    'modern': {
-        'keywords': ['modern', 'city', 'urban', 'metropolitan'],
-        'weight': 1.1
-    },
-    'nature': {
-        'keywords': ['nature', 'garden', 'park', 'river', 'nile'],
-        'weight': 1.2
-    },
-    'religious': {
-        'keywords': ['mosque', 'church', 'religious', 'spiritual'],
-        'weight': 1.1
-    }
-}
-
-class CityRequest(BaseModel):
-    city_description: str
-
-def extract_features(text: str) -> list:
-    """Extract relevant features from the text with their weights."""
-    text = text.lower()
-    found_features = []
-    for feature, data in FEATURES.items():
-        if any(keyword in text for keyword in data['keywords']):
-            found_features.append({
-                'name': feature,
-                'weight': data['weight']
-            })
-    return found_features
-
-@app.get("/api/cities")
-async def get_cities(request: CityRequest):
-    try:
-        city_description = request.city_description
-        if not city_description:
-            raise HTTPException(status_code=400, detail="City description cannot be empty")
-            
-        conn = None
-        cur = None
-        try:
-            conn = psycopg2.connect(**DB_Prams)
-            cur = conn.cursor()
-            
-            # Extract features from the description
-            features = extract_features(city_description)
-            
-            # Get the user messages embedding
-            embedding_response = requests.post(EMBEDDING_API_URL, json={"text": city_description})
-
-            
-            if embedding_response.status_code != 200:
-                raise HTTPException(status_code=500, detail="Failed to get embedding from embedding service")
-            
-            try:
-                user_msgs_embedding = embedding_response.json()
-                if "embedding" not in user_msgs_embedding:
-                    raise HTTPException(status_code=500, detail="Invalid embedding response format")
-            except json.JSONDecodeError:
-                raise HTTPException(status_code=500, detail="Invalid JSON response from embedding service")
-                
-
-            
-            # Base query with semantic similarity
-            base_query = """
-                WITH city_scores AS (
-                    SELECT 
-                        name, 
-                        description,
-                        longitude,
-                        latitude,
-                        1 - (embedding <=> %s::vector) AS semantic_similarity,
-                        CASE 
-            """
-            
-            # Add feature-based scoring
-            if features:
-                feature_conditions = []
-                for feature in features:
-                    feature_name = feature['name']
-                    weight = feature['weight']
-                    keywords = FEATURES[feature_name]['keywords']
-                    keyword_conditions = " OR ".join([f"description ILIKE %s OR name ILIKE %s" for _ in keywords])
-                    feature_conditions.append(f"WHEN ({keyword_conditions}) THEN {weight}")
-                base_query += "\n".join(feature_conditions)
-            else:
-                base_query += "WHEN 1=1 THEN 1"
-                
-            base_query += """
-                        ELSE 1
-                        END as feature_score
-                    FROM states
-                )
-                SELECT 
-                    name,
-                    description,
-                    longitude,
-                    latitude,
-                    (semantic_similarity * 0.7 + feature_score * 0.3) as combined_score
-                FROM city_scores
-                ORDER BY combined_score DESC
-                LIMIT 3
-            """
-            
-            # Prepare parameters for the query
-            params = [user_msgs_embedding["embedding"]]
-            if features:
-                for feature in features:
-                    feature_name = feature['name']
-                    keywords = FEATURES[feature_name]['keywords']
-                    for keyword in keywords:
-                        params.extend([f'%{keyword}%', f'%{keyword}%'])
-            
-
-            
-            # Execute the query
-            cur.execute(base_query, params)
-            cities = cur.fetchall()
-
-            if len(cities) < 3:
-                return {"top_cities": [], "message": "No cities found matching your description"}
-            
-            cities_list = [{
-                "name": city[0],
-                "description": city[1],
-                "longitude": city[2],
-                "latitude": city[3],
-            } for city in cities]
-            
-            return {"top_cities": cities_list}
-
-        except Exception as e:
-
-            raise HTTPException(status_code=500, detail=str(e))
-        finally:
-            if cur:
-                cur.close()
-            if conn:
-                conn.close()
-    except Exception as e:
-        raise HTTPException(status_code=500, detail=str(e))
-
-if __name__ == "__main__":
-    import uvicorn
-    uvicorn.run(app, host="0.0.0.0", port=3000)
-
-
